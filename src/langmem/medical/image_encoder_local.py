"""
æœ¬åœ°BiomedCLIPæ¨¡å‹ç®¡ç†
å¤„ç†æ¨¡å‹ä¸‹è½½ã€ç¼“å­˜å’Œå¾®è°ƒ
"""

import os
import logging
from pathlib import Path
from typing import Optional, Dict, Any
import json

import torch
import numpy as np
from PIL import Image
from transformers import AutoModel, AutoProcessor

logger = logging.getLogger(__name__)


class LocalBiomedCLIP:
    """æœ¬åœ°BiomedCLIPæ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(
        self,
        model_name: str = "microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224",
        cache_dir: Optional[str] = None,
        device: Optional[str] = None
    ):
        """åˆå§‹åŒ–æœ¬åœ°BiomedCLIPæ¨¡å‹
        
        Args:
            model_name: HuggingFaceæ¨¡å‹åç§°
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
            device: è®¡ç®—è®¾å¤‡
        """
        self.model_name = model_name
        self.cache_dir = cache_dir or os.path.expanduser("~/.cache/langmem/biomedclip")
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        self._model = None
        self._processor = None
        self._is_finetuned = False
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        Path(self.cache_dir).mkdir(parents=True, exist_ok=True)
        
    def download_model(self, force_download: bool = False):
        """ä¸‹è½½BiomedCLIPæ¨¡å‹åˆ°æœ¬åœ°
        
        Args:
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
        """
        print(f"ğŸ“¥ ä¸‹è½½BiomedCLIPæ¨¡å‹åˆ°: {self.cache_dir}")
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            model_path = Path(self.cache_dir) / "model"
            if model_path.exists() and not force_download:
                print("âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return
            
            # ä¸‹è½½æ¨¡å‹å’Œå¤„ç†å™¨
            print("ğŸ”„ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
            processor = AutoProcessor.from_pretrained(
                self.model_name,
                cache_dir=str(model_path / "processor")
            )
            
            model = AutoModel.from_pretrained(
                self.model_name,
                cache_dir=str(model_path / "model")
            )
            
            # ä¿å­˜é…ç½®ä¿¡æ¯
            config = {
                "model_name": self.model_name,
                "download_time": str(torch.utils.data.get_worker_info()),
                "device": self.device,
                "model_size_mb": self._get_model_size(model)
            }
            
            with open(model_path / "config.json", "w") as f:
                json.dump(config, f, indent=2)
            
            print("âœ… BiomedCLIPæ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            print(f"ğŸ“Š æ¨¡å‹å¤§å°: {config.get('model_size_mb', 'Unknown')}MB")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            raise
    
    def _get_model_size(self, model) -> float:
        """è®¡ç®—æ¨¡å‹å¤§å°(MB)"""
        param_size = 0
        for param in model.parameters():
            param_size += param.nelement() * param.element_size()
        buffer_size = 0
        for buffer in model.buffers():
            buffer_size += buffer.nelement() * buffer.element_size()
        size_mb = (param_size + buffer_size) / 1024**2
        return round(size_mb, 2)
    
    def load_model(self):
        """åŠ è½½æœ¬åœ°BiomedCLIPæ¨¡å‹"""
        if self._model is not None:
            return
            
        print(f"ğŸ”„ åŠ è½½BiomedCLIPæ¨¡å‹åˆ° {self.device}...")
        
        try:
            model_path = Path(self.cache_dir) / "model"
            
            if not model_path.exists():
                print("âŒ æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½...")
                self.download_model()
            
            # åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹
            self._processor = AutoProcessor.from_pretrained(
                str(model_path / "processor")
            )
            
            self._model = AutoModel.from_pretrained(
                str(model_path / "model")
            ).to(self.device)
            
            self._model.eval()
            
            print("âœ… BiomedCLIPæ¨¡å‹åŠ è½½å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å°è¯•é‡æ–°ä¸‹è½½æ¨¡å‹...")
            self.download_model(force_download=True)
            raise
    
    def encode_image(self, image_path: str) -> np.ndarray:
        """ç¼–ç å•å¼ å›¾åƒ"""
        if self._model is None:
            self.load_model()
        
        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path).convert("RGB")
            
            # é¢„å¤„ç†
            inputs = self._processor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                outputs = self._model.get_image_features(**inputs)
                features = outputs.cpu().numpy().flatten()
            
            return features
            
        except Exception as e:
            logger.error(f"å›¾åƒç¼–ç å¤±è´¥ {image_path}: {e}")
            raise
    
    def prepare_for_finetuning(
        self,
        bone_age_dataset: Optional[Dict] = None,
        learning_rate: float = 1e-5,
        freeze_backbone: bool = True
    ):
        """å‡†å¤‡éª¨é¾„å¾®è°ƒ
        
        Args:
            bone_age_dataset: éª¨é¾„æ•°æ®é›†
            learning_rate: å­¦ä¹ ç‡
            freeze_backbone: æ˜¯å¦å†»ç»“ä¸»å¹²ç½‘ç»œ
        """
        if self._model is None:
            self.load_model()
        
        print("ğŸ¯ å‡†å¤‡BiomedCLIPéª¨é¾„å¾®è°ƒ...")
        
        # å†»ç»“ä¸»å¹²ç½‘ç»œå‚æ•°
        if freeze_backbone:
            for param in self._model.vision_model.parameters():
                param.requires_grad = False
            print("ğŸ”’ å·²å†»ç»“è§†è§‰ä¸»å¹²ç½‘ç»œ")
        
        # æ·»åŠ éª¨é¾„å›å½’å¤´
        self._add_bone_age_head()
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        trainable_params = filter(lambda p: p.requires_grad, self._model.parameters())
        optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)
        
        print(f"âœ… å¾®è°ƒå‡†å¤‡å®Œæˆï¼Œå­¦ä¹ ç‡: {learning_rate}")
        return optimizer
    
    def _add_bone_age_head(self):
        """æ·»åŠ éª¨é¾„å›å½’å¤´"""
        # è·å–ç‰¹å¾ç»´åº¦
        feature_dim = self._model.config.projection_dim
        
        # æ·»åŠ å›å½’å¤´
        self._model.bone_age_head = torch.nn.Sequential(
            torch.nn.Linear(feature_dim, 256),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.1),
            torch.nn.Linear(256, 1)  # è¾“å‡ºéª¨é¾„å€¼
        ).to(self.device)
        
        print("ğŸ”§ å·²æ·»åŠ éª¨é¾„å›å½’å¤´")
    
    def finetune_on_bone_age(
        self,
        train_data: list,
        epochs: int = 10,
        batch_size: int = 8
    ):
        """åœ¨éª¨é¾„æ•°æ®ä¸Šå¾®è°ƒ
        
        Args:
            train_data: è®­ç»ƒæ•°æ® [(image_path, bone_age), ...]
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        if not hasattr(self._model, 'bone_age_head'):
            optimizer = self.prepare_for_finetuning()
        else:
            trainable_params = filter(lambda p: p.requires_grad, self._model.parameters())
            optimizer = torch.optim.AdamW(trainable_params, lr=1e-5)
        
        print(f"ğŸ¯ å¼€å§‹éª¨é¾„å¾®è°ƒ: {len(train_data)}ä¸ªæ ·æœ¬, {epochs}è½®")
        
        criterion = torch.nn.MSELoss()
        self._model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            num_batches = 0
            
            # ç®€å•çš„æ‰¹æ¬¡å¤„ç†
            for i in range(0, len(train_data), batch_size):
                batch = train_data[i:i+batch_size]
                
                # å¤„ç†æ‰¹æ¬¡æ•°æ®
                images = []
                targets = []
                
                for image_path, bone_age in batch:
                    try:
                        image = Image.open(image_path).convert("RGB")
                        images.append(image)
                        targets.append(bone_age)
                    except Exception as e:
                        logger.warning(f"è·³è¿‡æ— æ•ˆå›¾åƒ {image_path}: {e}")
                        continue
                
                if not images:
                    continue
                
                # é¢„å¤„ç†
                inputs = self._processor(images=images, return_tensors="pt")
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                targets = torch.tensor(targets, dtype=torch.float32).to(self.device)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                
                # æå–ç‰¹å¾
                image_features = self._model.get_image_features(**inputs)
                
                # éª¨é¾„é¢„æµ‹
                predictions = self._model.bone_age_head(image_features).squeeze()
                
                # è®¡ç®—æŸå¤±
                loss = criterion(predictions, targets)
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
            
            avg_loss = total_loss / max(1, num_batches)
            print(f"Epoch {epoch+1}/{epochs}, å¹³å‡æŸå¤±: {avg_loss:.4f}")
        
        self._is_finetuned = True
        print("âœ… éª¨é¾„å¾®è°ƒå®Œæˆï¼")
        
        # ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
        self.save_finetuned_model()
    
    def save_finetuned_model(self):
        """ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹"""
        if not self._is_finetuned:
            print("âš ï¸ æ¨¡å‹å°šæœªå¾®è°ƒï¼Œè·³è¿‡ä¿å­˜")
            return
        
        save_path = Path(self.cache_dir) / "finetuned_bone_age"
        save_path.mkdir(exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€
        torch.save({
            'model_state_dict': self._model.state_dict(),
            'is_finetuned': True,
            'model_name': self.model_name
        }, save_path / "model.pt")
        
        print(f"ğŸ’¾ å¾®è°ƒæ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_finetuned_model(self):
        """åŠ è½½å¾®è°ƒåçš„æ¨¡å‹"""
        save_path = Path(self.cache_dir) / "finetuned_bone_age" / "model.pt"
        
        if not save_path.exists():
            print("âŒ æœªæ‰¾åˆ°å¾®è°ƒæ¨¡å‹")
            return False
        
        try:
            # å…ˆåŠ è½½åŸºç¡€æ¨¡å‹
            self.load_model()
            
            # æ·»åŠ å›å½’å¤´
            self._add_bone_age_head()
            
            # åŠ è½½å¾®è°ƒæƒé‡
            checkpoint = torch.load(save_path, map_location=self.device)
            self._model.load_state_dict(checkpoint['model_state_dict'])
            
            self._is_finetuned = True
            print("âœ… å¾®è°ƒæ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return True
            
        except Exception as e:
            logger.error(f"å¾®è°ƒæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def predict_bone_age(self, image_path: str) -> float:
        """é¢„æµ‹éª¨é¾„ï¼ˆéœ€è¦å¾®è°ƒåçš„æ¨¡å‹ï¼‰"""
        if not self._is_finetuned:
            raise ValueError("éœ€è¦å…ˆå¾®è°ƒæ¨¡å‹æ‰èƒ½é¢„æµ‹éª¨é¾„")
        
        # ç¼–ç å›¾åƒ
        image = Image.open(image_path).convert("RGB")
        inputs = self._processor(images=image, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            # æå–ç‰¹å¾
            image_features = self._model.get_image_features(**inputs)
            
            # é¢„æµ‹éª¨é¾„
            bone_age = self._model.bone_age_head(image_features).squeeze()
            
            return bone_age.item()


def setup_local_biomedclip():
    """è®¾ç½®æœ¬åœ°BiomedCLIPç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®æœ¬åœ°BiomedCLIPç¯å¢ƒ...")
    
    # åˆ›å»ºæœ¬åœ°æ¨¡å‹ç®¡ç†å™¨
    biomedclip = LocalBiomedCLIP()
    
    # ä¸‹è½½æ¨¡å‹
    biomedclip.download_model()
    
    return biomedclip


if __name__ == "__main__":
    # æµ‹è¯•æœ¬åœ°BiomedCLIP
    biomedclip = setup_local_biomedclip()
    
    print("ğŸ§ª æµ‹è¯•å›¾åƒç¼–ç ...")
    # è¿™é‡Œéœ€è¦çœŸå®çš„åŒ»å­¦å›¾åƒè·¯å¾„
    # features = biomedclip.encode_image("test_hand_xray.jpg")
    # print(f"ç‰¹å¾ç»´åº¦: {features.shape}")
    
    print("âœ… æœ¬åœ°BiomedCLIPè®¾ç½®å®Œæˆï¼")