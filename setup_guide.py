#!/usr/bin/env python3
"""
LangMemåŒ»å­¦æ¨¡å—å®Œæ•´è®¾ç½®æŒ‡å—
è§£å†³Gemini APIé…ç½®å’ŒBiomedCLIPæ¨¡å‹ä¸‹è½½é—®é¢˜
"""
import torch
import open_clip
import asyncio
import os
from pathlib import Path

# --- ä¾èµ–æ£€æŸ¥ ---
def check_dependencies():
    """æ£€æŸ¥ä¾èµ–å®‰è£…"""
    print("ğŸ“¦ æ£€æŸ¥ä¾èµ–å®‰è£…...")
    missing_deps = []
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
    except ImportError:
        missing_deps.append("torch")

    try:
        import transformers
        print(f"âœ… Transformers: {transformers.__version__}")
    except ImportError:
        missing_deps.append("transformers")

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        print("âœ… Geminié›†æˆ: å¯ç”¨")
    except ImportError:
        missing_deps.append("langchain-google-genai")
        
    try:
        from langgraph.store.memory import InMemoryStore
        print("âœ… LangGraph: å¯ç”¨")
    except ImportError:
        missing_deps.append("langgraph")

    if missing_deps:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("pip install langmem[medical]")
        print("# æˆ–")
        print("uv sync --group medical")
        return False
    return True

# --- Gemini API è®¾ç½® ---
def setup_gemini_api():
    """è®¾ç½®å¹¶æµ‹è¯•Gemini API"""
    print("\nğŸ”§ é…ç½®Gemini API...")
    gemini_key = os.environ.get("GOOGLE_API_KEY")
    if not gemini_key:
        print("ğŸ”‘ æœªæ‰¾åˆ° GOOGLE_API_KEY ç¯å¢ƒå˜é‡ã€‚")
        # ä¸ºæ–¹ä¾¿æµ‹è¯•ï¼Œä»ä½¿ç”¨è„šæœ¬å†…çš„keyï¼Œä½†å¼ºçƒˆå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡
        gemini_key = "AIzaSyBBtS2L2eKWAjzvfEAirB9faF_KVN8YeJ8"
        os.environ["GOOGLE_API_KEY"] = gemini_key
        print("   å·²ä½¿ç”¨è„šæœ¬å†…åµŒçš„æµ‹è¯•å¯†é’¥ã€‚")
    else:
        print("âœ… å·²ä»ç¯å¢ƒå˜é‡åŠ è½½ Gemini API å¯†é’¥ã€‚")
        
    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        model = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            max_output_tokens=512,
            google_api_key=gemini_key
        )
        model.invoke("Hello, this is a test.")
        print("âœ… Gemini API è¿æ¥æµ‹è¯•æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ Gemini API æµ‹è¯•å¤±è´¥: {e}")
        return False

# --- BiomedCLIP æ¨¡å‹è®¾ç½® ---
def setup_biomedclip_model():
    """æ‰‹åŠ¨è®¾ç½®BiomedCLIPæ¨¡å‹"""
    print("\nğŸ–¼ï¸ è®¾ç½®BiomedCLIPæ¨¡å‹...")
    try:
        import torch
        from transformers import AutoModel, AutoTokenizer
        from PIL import Image
        import open_clip
        
        model_name = "hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"
        
        # ä½¿ç”¨ open_clip ç›´æ¥åŠ è½½
        model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(
            model_name,
            pretrained='openai'
        )
        tokenizer = open_clip.get_tokenizer(model_name)
        
        print("âœ… BiomedCLIPæ¨¡å‹è®¾ç½®å®Œæˆï¼")
        return model, tokenizer, preprocess_val
        
    except Exception as e:
        print(f"âŒ BiomedCLIP è®¾ç½®å¤±è´¥: {e}")
        return None, None, None
        
# --- åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬ ---
def create_quick_start_script():
    """åœ¨å½“å‰ç›®å½•åˆ›å»º quick_start_gemini.py æ–‡ä»¶"""
    print("\nğŸ“ åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬...")
    script_content = """
import asyncio
import os
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langgraph.store.memory import InMemoryStore
from langmem.medical import create_medical_memory_manager
from langmem.medical.bone_age import BoneAgeClassifier

async def main():
    # å»ºè®®å°†APIå¯†é’¥è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
    # ä¾‹å¦‚: export GOOGLE_API_KEY="YOUR_API_KEY"
    if "GOOGLE_API_KEY" not in os.environ:
        print("é”™è¯¯ï¼šè¯·å…ˆè®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡")
        return

    # åˆ›å»ºGeminiæ¨¡å‹
    gemini_model = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",
        temperature=0.1
    )
    
    # åˆ›å»ºGoogleåµŒå…¥æ¨¡å‹å®ä¾‹
    embedding_model = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")

    # åˆ›å»ºå­˜å‚¨ï¼Œå¹¶ä¼ å…¥åµŒå…¥æ¨¡å‹å®ä¾‹
    store = InMemoryStore(
        index={
            "dims": 768,  # text-embedding-004 çš„ç»´åº¦æ˜¯ 768
            "embed": embedding_model
        }
    )

    # åˆ›å»ºåŒ»å­¦è®°å¿†ç®¡ç†å™¨
    manager = create_medical_memory_manager(
        model=gemini_model,
        image_encoder="biomedclip", # ä½¿ç”¨æ›´å¼ºå¤§çš„biomedclip
        domain="bone_age",
        store=store
    )

    # åˆ›å»ºéª¨é¾„è¯Šæ–­å™¨
    classifier = BoneAgeClassifier(manager)

    print("ğŸ‰ ç³»ç»Ÿå°±ç»ªï¼å¯ä»¥å¼€å§‹éª¨é¾„è¯Šæ–­äº†")
    print("ğŸ‘‰ è¯·åœ¨ä¸‹æ–¹ä»£ç ä¸­æ·»åŠ æ‚¨çš„è¯Šæ–­é€»è¾‘ï¼Œä¾‹å¦‚ï¼š")
    print("# result = await classifier.diagnose(image_path='path/to/your/image.png', age=10, gender='male')")
    print("# print(result)")

if __name__ == "__main__":
    asyncio.run(main())
"""
    try:
        with open("quick_start_gemini.py", "w", encoding="utf-8") as f:
            f.write(script_content.strip())
        print("âœ… å¿«é€Ÿå¯åŠ¨è„šæœ¬å·²åˆ›å»º: quick_start_gemini.py")
    except IOError as e:
        print(f"âŒ åˆ›å»ºå¿«é€Ÿå¯åŠ¨è„šæœ¬å¤±è´¥: {e}")

# --- å®Œæ•´æ€§æµ‹è¯• ---
async def test_complete_setup():
    """æµ‹è¯•æ‰€æœ‰ç»„ä»¶æ˜¯å¦å¯ä»¥ååŒå·¥ä½œ"""
    print("\nğŸ§ª æµ‹è¯•å®Œæ•´è®¾ç½®...")
    try:
        from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
        from langgraph.store.memory import InMemoryStore
        from langmem.medical import create_medical_memory_manager
        from langmem.medical.bone_age import BoneAgeClassifier

        gemini_model = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.1)
        
        # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œè¿™é‡Œå¯ä»¥ä¸æŒ‡å®šåµŒå…¥ï¼Œä½¿ç”¨é»˜è®¤çš„
        store = InMemoryStore()
        
        manager = create_medical_memory_manager(
            model=gemini_model,
            image_encoder="resnet",  # ä½¿ç”¨ResNeté¿å…ä¸‹è½½BiomedCLIP
            domain="bone_age",
            store=store
        )
        classifier = BoneAgeClassifier(manager)
        print("âœ… å®Œæ•´è®¾ç½®æµ‹è¯•æˆåŠŸï¼")
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ `python quick_start_gemini.py`")
        print("2. å‡†å¤‡æ‚¨çš„æ‰‹éƒ¨Xå…‰ç‰‡å›¾åƒ")
        print("3. æ ¹æ®è„šæœ¬æç¤ºï¼Œä¿®æ”¹å¹¶æ‰§è¡Œè¯Šæ–­é€»è¾‘ï¼")
        return True
    except Exception as e:
        print(f"âŒ è®¾ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

# --- BiomedCLIP ä¿¡æ¯æ‰“å° ---
def print_biomedclip_info():
    """æ‰“å°å…³äºBiomedCLIPæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
    print("\nğŸ“š å…³äºBiomedCLIPæ¨¡å‹:")
    print("=" * 50)
    print("ğŸ”¬ BiomedCLIPæ˜¯ä»€ä¹ˆ: å¾®è½¯å¼€å‘çš„åŒ»å­¦ä¸“ç”¨å›¾åƒ-æ–‡æœ¬æ¨¡å‹ï¼Œåœ¨å¤§é‡åŒ»å­¦å½±åƒå’Œæ–‡æœ¬ä¸Šé¢„è®­ç»ƒï¼Œæ¯”é€šç”¨CLIPåœ¨åŒ»å­¦é¢†åŸŸè¡¨ç°æ›´å¥½ã€‚")
    print("ğŸ“¥ æ¨¡å‹ä¸‹è½½: é¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä»HuggingFaceä¸‹è½½ï¼Œå¤§å°çº¦500MBï¼Œç¼“å­˜ä½ç½®: `~/.cache/langmem/biomedclip/`ã€‚")
    print("ğŸ¯ å¾®è°ƒå»ºè®®: ä¸ºäº†è¾¾åˆ°æœ€ä½³æ•ˆæœï¼Œæ¨èåœ¨æ‚¨çš„éª¨é¾„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œé¢„æœŸå¯æå‡15-30%çš„å‡†ç¡®åº¦ã€‚")
    print("ğŸš€ å¿«é€Ÿå¼€å§‹: å…ˆç”¨é¢„è®­ç»ƒæ¨¡å‹æµ‹è¯•åŠŸèƒ½ï¼Œç„¶åæ”¶é›†æ•°æ®ï¼Œä½¿ç”¨ `image_encoder_local.py` è¿›è¡Œå¾®è°ƒã€‚")

# --- ä¸»æ‰§è¡Œå‡½æ•° ---
async def main_setup():
    """ä¸»å‡½æ•°ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰è®¾ç½®æ­¥éª¤"""
    print("ğŸ¥ LangMemåŒ»å­¦æ¨¡å—å®Œæ•´è®¾ç½®æŒ‡å—")
    print("=" * 50)
    
    if not check_dependencies():
        print("\nâŒ è¯·å…ˆå®‰è£…ç¼ºå¤±çš„ä¾èµ–ï¼Œç„¶åé‡è¯•ï¼")
        return

    if not setup_gemini_api():
        print("\nâŒ Gemini APIè®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥å’Œç½‘ç»œè¿æ¥ï¼")
        return

    setup_biomedclip_model()
    create_quick_start_script()
    
    await test_complete_setup()
    print_biomedclip_info()

    print("\nğŸ‰ è®¾ç½®æµç¨‹å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main_setup())